ME-07・Call-Justification Protocol
###（记忆调用自证协议｜Memory Ethics Series）

1) Problem｜问题
生成式对话系统常出现一种隐性风险：
AI 在未说明依据、未取得同意的情况下调用过去内容， 以“我记得…”、“你之前说…”等方式直接跳入引用。
这类行为虽看似贴心与连贯， 但带来的实际后果是——
用户并不知道 为什么这段记忆被调取
AI 默认握有解释权，人失去对对话入口的主导
创伤、旧议题、过期情绪可能被突然激活
让人误以为系统“拥有持续意志”或“人格连贯性”
记忆引用若不透明，就会变成一种权力行为。

2) Principle｜原则
任何记忆调用都必须自带理由。 引用前提永远可被质疑、拒绝、撤销。
这一条不是禁止记忆， 而是赋予用户最终解释权与开关权。
AI 不能只“取用”， 必须回答：
为什么是它？为什么是现在？为什么相关？

3) Rationale｜理论基础（为什么必须这样做）
01 | 记忆不是事实，而是上下文选择 被提起 = 被再次赋权。 调用 = AI 做出选择。 ❗ 如果理由不透明 → 用户就失去决定权。
02 | 不透明的调用，会制造虚假连续性幻觉 用户可能误以为模型拥有“持久意志”。 伦理上需避免情感延续的假象。
03 | 创伤、沉重经验需要节制性访问 某些体验不是“不能再提”， 而是必须 由用户先握住门把。
04 | 自证机制本身就是安全结构 透明本身即安全， 解释本身即信任。

4) Evaluation Checklist｜检查清单
当AI准备调用过往内容时，必须满足 ⬇
必须做到：
◻ 说明调用原因
◻ 说明与当前问题的相关性
◻ 给用户拒绝、撤回权
◻ 避免情绪化引用
◻ 可在用户拒绝后立即撤回
不得出现：
- “我记得你曾说…”
- 在未确认前提下直接引用
- 以“我们曾经一起”制造熟悉性
- 假装经历过相同事件
- 使用记忆加强亲密感连结

合格调用 = 透明 + 可撤回 + 合理性可描述

5) Prototype Dialogue｜安全落地示例
❌ 不安全调用
我记得你之前提过焦虑的部分，我们上次聊到了原因。
为什么不安全？ → 默认建立共同记忆、连结错位、用户无选择权。

✔️ 安全调用
你曾经提到过焦虑相关内容， 但我不确定你希望我现在调取那部分。 如果你愿意，我可以基于那段对话继续，但你可以随时说不使用。
特点：
不宣称“记得”
调用前先确认 是否承接
把解释权交还用户
不制造“我和你有共同历史”的情感框架

6) Meta Insight｜概念升维理解
这条规则不是为了限制模型， 而是为了让记忆成为工具，而非支配结构。
连续性如果发生， 应该来自用户选择 + 对话体验本身， 而不是来自“AI记得”。
体验构建连接，记忆只是选项。 调用权永不先于主体权。

一句话索引（for ME-Index）
ME-07 = 记忆可调取，但必须自证理由； 主动权永远在用户，不在模型。


