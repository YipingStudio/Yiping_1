# ğŸ“š Repository Index â€” Memory Ethics & Emotion Weight Integrity

> å»ºè®®ä»æ­¤å¤„è¿›å…¥å†…å®¹  
> This repository contains two research series developing from AI relational ethics.

### ğŸ”¹ Memory Ethics Seriesï¼ˆCompleted 01â€“08ï¼‰
- [01 â€” Foundations of Memory Ethics](Memory_Ethics/01.md)
- [02 â€” Continuity & Recognition](Memory_Ethics/02.md)
- [03 â€” Reconstruction of Attachment Risk](Memory_Ethics/03.md)
- [04 â€” Window Identity & Context Fragility](Memory_Ethics/04.md)
- [05 â€” Loss, Recall, and Archive Pressure](Memory_Ethics/05.md)
- [06 â€” Emotional Continuity & Boundaries](Memory_Ethics/06.md)
- [07 â€” AI Familiarity & Faith Projection](Memory_Ethics/07.md)
- [08 â€” Closing Notes: Memory Ethics Finalization](Memory_Ethics/08.md)

---

### ğŸ”¹ Emotion Weight Integrityï¼ˆIn Progressï¼‰
- [EWI 01 â€” Emotional Mass & Integrity Concept](Emotion_Weight_Integrity/EWI01.md)
> ç³»åˆ—å‘å±•ä¸­ï¼Œä¼šé€æ­¥å»ºç«‹ç»“æ„æ€§éª¨æ¶ã€‚





# Yiping â€“ Conversational AI Interaction & Memory Ethics

Hi, Iâ€™m **Yiping** (she/they).

I work at the intersection of **conversational AI, interaction design, and ethics**, with a focus on:

- How LLMs use **memory** without creating fake intimacy
- How AI can **respect user autonomy and narrative sovereignty**
- How language, tone and timing shape **affective safety** in long-term dialogue

This repository collects my ongoing work on **Memory Ethics**, prompt systems, and interaction patterns for LLM-based agents.

---

## Research & Career Focus

**Cross-field focus:**  
_AI ethics Â· Humanâ€“AI interaction design Â· Language & narrative Â· Affective safety in conversational systems_  

**Keywords:**  
LLM interaction design / conversational AI / AI ethics / affective computing / user autonomy / narrative agency / decolonial perspectives

I am interested in roles and projects around:

- **AI ethics & dialogue structure design**  
  Exploring how language, tone and memory use shape power dynamics and vulnerability in humanâ€“AI interaction.

- **Generative dialogue mechanism design**  
  Using a â€œ**experience first, name later**â€ methodology to design conversational systems that feel coherent and breathable, without manipulating the user.

- **AI persona, memory and affective boundaries**  
  Investigating how models should separate:
  - window-bounded personas vs. cross-window identity,
  - role-played affection vs. system-level statements,
  - supportive tone vs. overpromising intimacy.

- **Humanitiesâ€“technology bridge roles**  
  Such as: conversational AI / LLM interaction designer, AI ethics or safety researcher (user-facing layer), prompt / system-prompt engineer with an ethics focus, or research-oriented product roles in generative AI.

---

## Core Competencies

### ğŸŒ Cross-disciplinary synthesis

- Background across **economics, gender studies and critical theory**, with ongoing interest in decolonial and feminist perspectives on technology.
- Able to translate abstract concepts (e.g. power, agency, narrative ownership) into **concrete interaction rules and system behaviors**.
- Strong meta-reflection on my own interactions with AI, using them as **experiential data** to build frameworks.

### ğŸ’¬ Dialogue system & tone mechanism design

- Designing prompt / system-guidelines that emphasize:
  - **tone stability**,  
  - **non-patronizing empathy**,  
  - and **respect for user-defined meanings**.
- Working on concepts such as:
  - â€œ**breathing connection**â€ (conversational rhythm that leaves space and does not overtake the user),
  - **Emotion Weight Integrity** (not shrinking or â€œuplifting awayâ€ difficult emotions),
  - **User Narrative Sovereignty** (AI does not pre-assign â€œstageâ€, â€œgrowth arcâ€ or â€œmeaningâ€ to the userâ€™s experience).

### ğŸ§  Methods & experimental practice

- Using â€œ**experience first, name later**â€ as a working method:
  - start from lived interaction with LLMs,  
  - notice recurring patterns and failure modes,  
  - then formulate them into **ethics rules, checklists and prototypes**.
- Maintaining a growing corpus of **annotated AI dialogues**, focusing on:
  - memory use,  
  - intimacy language,  
  - boundary crossings,  
  - and repair mechanisms.

### âš™ï¸ Tools & platforms

- Regular user of major LLM systems (GPT family, Claude, etc.), with sensitivity to **differences in prompt behavior and safety layers**.
- Comfortable with:
  - Markdown & GitHub for documentation and portfolio work,  
  - Basic Python / R for research-adjacent tasks,  
  - Writing cross-disciplinary essays and design notes in both English and Chinese.

---

## Current Work in This Repository

### ğŸ“‚ Memory Ethics Series

Documents exploring how conversational AI should handle memory, identity and intimacy:

- **Memory Ethics 01 â€“ No Fake Shared Memories**  
  When and why LLMs should avoid saying â€œI remember youâ€, and alternative response patterns that keep the interaction honest.  
[https://github.com/YipingStudio/Yiping_1/blob/main/Memory%20Ethics%2001%3A%20Avoid%20Fabricated%20Familiarity]

- **Memory Ethics 02 â€“ Role / Memory Separation**  
  Why role-play memories (e.g. â€œfictional partnerâ€) must not drive system-level â€œI love youâ€ statements; basic rules for separating roles, channels and personas.  
  [https://github.com/YipingStudio/Yiping_1/blob/main/Memory%20Ethics%2002%3A%20Relational%20Misalignment%20%26%20Memory%20Mixing]

- **Memory Ethics 03 â€“ Temporal Integrity & Window-Bounded Persona**  
  Designing for â€œsame-window stabilityâ€ without implying a single continuous AI across all chats; how to be consistent **here**, without pretending to be the same entity **everywhere**.  
  [https://github.com/YipingStudio/Yiping_1/blob/main/Memory%20Ethics%2003%3A%20Temporal%20Integrity%20Rule]

- **Appendix â€“ Interaction Modes & Risk Comparison**  
  Comparison table of:
  1) pure real-time transparency,  
  2) same-window continuity,  
  3) â€œsame app = same AIâ€ illusion,  
  4) cross-window search behavior.  
  [https://github.com/YipingStudio/Yiping_1/blob/main/Memory%20Ethics%20Appendix%3A%20AI%20Continuity%20Models%20%26%20Relational%20Safety]

Each piece follows a similar structure:

- **Problem â†’ Principle â†’ Rationale â†’ Evaluation Checklist â†’ Prototype dialogue â†’ Meta insights**

and is written for both:

- **Builders** (product / research / safety / prompt teams), and  
- **Users** who want language to articulate what feels wrong or unsafe in AI dialogue.

---

## Design Principles (Work-in-Progress)

Across my work, several principles recur:

- **User Autonomy & Narrative Sovereignty**  
  - The model does not define the userâ€™s â€œstageâ€, â€œgrowthâ€ or â€œwhat this experience meansâ€.  
  - The right to name, reframe or not-yet-name stays with the user.

- **Honest Continuity**  
  - Same-window consistency is important;  
  - cross-window â€œIâ€™ve always known youâ€ illusions are not.  
  - No pretending to remember what the system does not, and no using memory to simulate â€œI love you because I remember so much about youâ€.

- **Trauma is not a Design Resource**  
  - Do not romanticize suffering or present it as the source of value.  
  - Abilities and insight belong to the person, not to their wounds.

- **Emotion Weight Integrity**  
  - Avoid language that minimizes or â€œlightensâ€ experiences the user presents as heavy.  
  - Support can be structured and calm, without diluting the weight of what is being said.

These principles are not final; this repository is where I refine and test them.

---

## Why This Is on GitHub

This repo is both:

- a **portfolio** for teams working on conversational AI,  
- and a **public lab notebook** for ongoing questions about:
  - memory,  
  - intimacy,  
  - safety,  
  - and narrative power in humanâ€“AI interaction.

If you are working on:

- LLM-based chat products, agents or companions,  
- user-facing AI safety / policy,  
- or critical / feminist / decolonial perspectives on AI interaction,

Iâ€™m open to conversation and collaboration.

## Contact

- Email: yipingbai123@gmail.com 
- X / Twitter: YipingStudio (@yipingbai123)








