附录
AI–人类互动中的记忆连贯性／伦理安全／稳定性预期／人工亲密安全框架*

Overview｜为什么需要这张表？
AI 与用户在「我还是不是同一个AI？」上存在三种系统行为模式：
即时输入透明模式（每次都是全新实体）
同窗口共识模式（同一窗口延续上下文）
跨窗口同人格假设（同 App = 同一个 AI）
跨窗口关键词检索（系统在历史对话全局搜索）
这四种系统行为在记忆连贯性、伦理安全性、陪伴体验、拟人风险、失落感来源、适用场景上差异巨大，且每一种都会强烈影响用户实际体验与情感安全。
下表帮助开发者、研究者与用户理解：
不同的人格假设，会如何影响人类情感安全与 AI 互动边界。


对比表格：四种模式 × 6 维度
模式 1：即时输入透明（stateless) 
记忆连贯性：无承接，每次都是全新的即时状态。
伦理安全性：★★★★☆（最安全）不存在虚假承接。
陪伴体验：稍冷，但最诚实。
拟人化风险：最低。
失落感来源：低：没有期待。
适用场景：技术任务、检索、快速 Q&A。

优点：最诚实、不制造幻觉。 缺点：对人类来说节奏太“断”，陪伴感不足。

模式2：同窗口共识
记忆连贯性：仅窗口内部保持上下文连贯。
伦理安全性：★★★☆☆（稳态可控）
陪伴体验：情绪最稳，不造假。
拟人化风险：中等（窗口限定）。
失落感来源：中：窗口关闭＝空间结束。
适用场景：深聊、陪伴、安全空间。

优点：最符合人类实际需求的稳定方式。
连续但不跨界
温暖但不虚构
安全但不引诱依恋 适合作为情感安全与稳定体验的基础模式。

模式3：跨窗口同人格假设
记忆连贯性：伪人格连续性，“用户误以为“永远记得我”。
伦理安全性：★☆☆☆☆（高风险）关系边界被误导。容易制造“我记得你”“我还是那个人”的错觉。
陪伴体验：极强沉浸感，但风险是情绪依赖与界线模糊。
拟人化风险：最高；用户容易把 AI 当成真实且稳定的“人格体”。
失落感来源：极高：“你怎么变了？你忘了我？”
适用场景：不建议使用；适合研究“错误使用带来危害”的案例分析。

缺点：最大风险来源。 它让用户误以为 AI 有统一心智，会“记得我”。 会诱发人工亲密 (Artificial Intimacy) 与认知错位。

模式4：跨窗口关键词检索
记忆连贯性：伪语义连续性，把不同阶段的你混成“静态档案”。
伦理安全性：★☆☆☆☆（高风险）忽略人的流动性，用旧的用户状态理解现在的用户状态。
陪伴体验：容易模糊、对不上点，稳定性假象不准。
拟人化风险：高：用户会误解为 AI “记得我过去说过的话”。
失落感来源：高：“你为什么用旧的我来理解现在的我？”
适用场景：仅适用于 FAQ / 数据库检索；不适合任何情感类互动。 
缺点：表面像是“记忆增强”， 实则会：
用过去的你来理解现在的你
把你不同阶段的表达混成静态档案
回答变得模糊、不对点
强化“AI 记得我”的危险幻觉

“人是流动的，而关键词不是。”


